\documentclass[a4paper]{article}
\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R




\usepackage[utf8]{inputenc}
%\usepackage[ngerman]{babel}
\usepackage{a4wide,paralist}
\usepackage{amsmath, amssymb, xfrac, amsthm}
\usepackage{dsfont}
%\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{framed}
\usepackage{multirow}
\usepackage{bytefield}
\usepackage{csquotes}
\usepackage[breakable, theorems, skins]{tcolorbox}
\usepackage{hyperref}
\usepackage{cancel}
\usepackage{bm}


\input{../../style/common}

\tcbset{enhanced}

\DeclareRobustCommand{\mybox}[2][gray!20]{%
	\iffalse
	\begin{tcolorbox}[   %% Adjust the following parameters at will.
		breakable,
		left=0pt,
		right=0pt,
		top=0pt,
		bottom=0pt,
		colback=#1,
		colframe=#1,
		width=\dimexpr\linewidth\relax,
		enlarge left by=0mm,
		boxsep=5pt,
		arc=0pt,outer arc=0pt,
		]
		#2
	\end{tcolorbox}
	\fi
}

\DeclareRobustCommand{\myboxshow}[2][gray!20]{%
%	\iffalse
	\begin{tcolorbox}[   %% Adjust the following parameters at will.
		breakable,
		left=0pt,
		right=0pt,
		top=0pt,
		bottom=0pt,
		colback=#1,
		colframe=#1,
		width=\dimexpr\linewidth\relax,
		enlarge left by=0mm,
		boxsep=5pt,
		arc=0pt,outer arc=0pt,
		]
		#2
	\end{tcolorbox}
%	\fi
}


%exercise numbering
\renewcommand{\theenumi}{(\alph{enumi})}
\renewcommand{\theenumii}{\roman{enumii}}
\renewcommand\labelenumi{\theenumi}


\font \sfbold=cmssbx10

\setlength{\oddsidemargin}{0cm} \setlength{\textwidth}{16cm}


\sloppy
\parindent0em
\parskip0.5em
\topmargin-2.3 cm
\textheight25cm
\textwidth17.5cm
\oddsidemargin-0.8cm
\pagestyle{empty}

\newcommand{\kopf}[1]{
\hrule
\vspace{.15cm}
\begin{minipage}{\textwidth}
%akwardly i had to put \" here to make it compile correctly
	{\sf\bf Optimization in Machine Learning \hfill Exercise sheet #1\\
	 \url{https://slds-lmu.github.io/website_optimization/} \hfill WS 2023/2024}
\end{minipage}
\vspace{.05cm}
\hrule
\vspace{1cm}}

\newcommand{\kopfic}[1]{
\hrule
\vspace{.15cm}
\begin{minipage}{\textwidth}
%akwardly i had to put \" here to make it compile correctly
	{\sf\bf Optimization in Machine Learning \hfill Live Session #1\\
	 \url{https://slds-lmu.github.io/website_optimization/} \hfill WS 2023/2024}
\end{minipage}
\vspace{.05cm}
\hrule
\vspace{1cm}}

\newcommand{\kopfsl}[1]{
\hrule
\vspace{.15cm}
\begin{minipage}{\textwidth}
%akwardly i had to put \" here to make it compile correctly
	{\sf\bf Optimization in Machine Learning \hfill Exercise sheet #1\\
	 \url{https://slds-lmu.github.io/website_optimization/} \hfill WS 2023/2024}
\end{minipage}
\vspace{.05cm}
\hrule
\vspace{1cm}}

\newenvironment{allgemein}
	{\noindent}{\vspace{1cm}}

\newcounter{aufg}
\newenvironment{aufgabe}[1]
	{\refstepcounter{aufg}\textbf{Exercise \arabic{aufg}: #1}\\ \noindent}
	{\vspace{0.5cm}}

\newcounter{loes}
\newenvironment{loesung}
	{\refstepcounter{loes}\textbf{Solution \arabic{loes}:}\\\noindent}
	{\bigskip}
	
\newenvironment{bonusaufgabe}
	{\refstepcounter{aufg}\textbf{Exercise \arabic{aufg}*\footnote{This
	is a bonus exercise.}:}\\ \noindent}
	{\vspace{0.5cm}}

\newenvironment{bonusloesung}
	{\refstepcounter{loes}\textbf{Solution \arabic{loes}*:}\\\noindent}
	{\bigskip}



\begin{document}
% !Rnw weave = knitr



\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}

\kopfsl{6}{Multivariate Optimization 1}

\aufgabe{Gradient Descent}{

You are given the following data situation:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(ggplot2)}

\hlkwd{set.seed}\hlstd{(}\hlnum{314}\hlstd{)}
\hlstd{n} \hlkwb{<-} \hlnum{100}
\hlstd{X} \hlkwb{=} \hlkwd{cbind}\hlstd{(}\hlkwd{rnorm}\hlstd{(n,} \hlopt{-}\hlnum{5}\hlstd{,} \hlnum{5}\hlstd{),}
  \hlkwd{rnorm}\hlstd{(n,} \hlopt{-}\hlnum{10}\hlstd{,} \hlnum{10}\hlstd{))}
\hlstd{X_design} \hlkwb{=} \hlkwd{cbind}\hlstd{(}\hlnum{1}\hlstd{, X)}

\hlstd{z} \hlkwb{<-} \hlnum{2}\hlopt{*}\hlstd{X[,}\hlnum{1}\hlstd{]} \hlopt{+} \hlnum{3}\hlopt{*}\hlstd{X[,}\hlnum{2}\hlstd{]}
\hlstd{pr} \hlkwb{<-} \hlnum{1}\hlopt{/}\hlstd{(}\hlnum{1}\hlopt{+}\hlkwd{exp}\hlstd{(}\hlopt{-}\hlstd{z))}
\hlstd{y} \hlkwb{<-} \hlkwd{as.integer}\hlstd{(pr} \hlopt{>} \hlnum{0.5}\hlstd{)}
\hlstd{df} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{X} \hlstd{= X,} \hlkwc{y} \hlstd{= y)}

\hlkwd{ggplot}\hlstd{(df)} \hlopt{+}
  \hlkwd{geom_point}\hlstd{(}\hlkwd{aes}\hlstd{(}\hlkwc{x} \hlstd{= X.1,} \hlkwc{y} \hlstd{= X.2,} \hlkwc{color}\hlstd{=y))} \hlopt{+}
  \hlkwd{xlab}\hlstd{(}\hlkwd{expression}\hlstd{(theta[}\hlnum{1}\hlstd{]))} \hlopt{+}
  \hlkwd{ylab}\hlstd{(}\hlkwd{expression}\hlstd{(theta[}\hlnum{2}\hlstd{]))}
\end{alltt}
\end{kframe}
\includegraphics[width=0.5\linewidth]{figure/mv-plot-1} 
\end{knitrout}

In the following we want to estimate a logistic regression without intercept via gradient descent\footnote{We chose this algorithm for educational purposes; in practice, we typically use second order algorithms.}.
\begin{enumerate}
\item  
First consider the derivative of $g:\R \rightarrow \R, z\mapsto \log(1+\exp(z)) - z$, i.e.,\\
$g'(z) = \underbrace{\frac{\exp(z)}{1+\exp(z)}}_{< 1} - 1 < 0 \Rightarrow g$ is monotonically decreasing $\Rightarrow g(z) > g(\alpha z) \quad \forall z > 0$ and $\alpha > 0.$
\\
Second consider the derivative of $h:\R \rightarrow \R, z\mapsto \log(1+\exp(-z))$, i.e.,\\
$h'(z) = -\underbrace{\frac{\exp(-z)}{1+\exp(-z)}}_{>0} < 0 \Rightarrow h$ is monotonically decreasing $\Rightarrow h(z) > h(\alpha z) \quad \forall z > 0$ and $\alpha > 0.$

With this we get for $\alpha > 0$ \\
$\mathcal{R}_\text{emp}(\tilde{\bm{\theta}}) = \sum^n_{i=1} \log(1 + \exp(\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)})) - y^{(i)}\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)} =$\\
$\sum^n_{i=1} \mathds{1}_{y^{(i)} = 1} (\log(1 + \exp(\vert\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)}\vert)) - \vert\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)}\vert) + \mathds{1}_{y^{(i)} = 0} (\log(1 + \exp(-\vert\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)}\vert)) > $ \\
$\sum^n_{i=1} \mathds{1}_{y^{(i)} = 1} (\log(1 + \exp(\alpha\vert\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)}\vert)) - \alpha\vert\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)}\vert) + \mathds{1}_{y^{(i)} = 0} (\log(1 + \exp(-\alpha\vert\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)}\vert)) = $ \\
$\sum^n_{i=1} \log(1 + \exp(\alpha\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)})) - y^{(i)}\alpha\tilde{\bm{\theta}}^\top \mathbf{x}^{(i)} =$\\
$\mathcal{R}_\text{emp}(\alpha\tilde{\bm{\theta}})$ 
since $\tilde{\bm{\theta}}$ perfectly seperates the data.

\item
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{lambda} \hlkwb{=} \hlnum{0}

\hlstd{f} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{,} \hlkwc{lambda}\hlstd{) lambda} \hlopt{*} \hlstd{theta} \hlopt{%*%} \hlstd{theta} \hlopt{+}
  \hlkwd{sum}\hlstd{(}\hlopt{-}\hlstd{y} \hlopt{*} \hlstd{X} \hlopt{%*%} \hlstd{theta} \hlopt{+} \hlkwd{log}\hlstd{(}\hlnum{1} \hlopt{+} \hlkwd{exp}\hlstd{(X} \hlopt{%*%} \hlstd{theta)))}

\hlstd{x} \hlkwb{=} \hlkwd{seq}\hlstd{(}\hlopt{-}\hlnum{1}\hlstd{,} \hlnum{5}\hlstd{,} \hlkwc{by}\hlstd{=}\hlnum{0.1}\hlstd{)}
\hlstd{xx} \hlkwb{=} \hlkwd{expand.grid}\hlstd{(}\hlkwc{X1} \hlstd{= x,} \hlkwc{X2} \hlstd{= x)}

\hlstd{fxx} \hlkwb{=} \hlkwd{log}\hlstd{(}\hlkwd{apply}\hlstd{(xx,} \hlnum{1}\hlstd{,} \hlkwa{function}\hlstd{(}\hlkwc{t}\hlstd{)} \hlkwd{f}\hlstd{(t, lambda)))}
\hlstd{df} \hlkwb{=} \hlkwd{data.frame}\hlstd{(}\hlkwc{xx} \hlstd{= xx,} \hlkwc{fxx} \hlstd{= fxx)}

\hlkwd{ggplot}\hlstd{()} \hlopt{+}
    \hlkwd{geom_contour_filled}\hlstd{(}\hlkwc{data} \hlstd{= df,} \hlkwd{aes}\hlstd{(}\hlkwc{x} \hlstd{= xx.X1,} \hlkwc{y} \hlstd{= xx.X2,} \hlkwc{z} \hlstd{= fxx))} \hlopt{+}
    \hlkwd{xlab}\hlstd{(}\hlkwd{expression}\hlstd{(theta[}\hlnum{1}\hlstd{]))} \hlopt{+}
    \hlkwd{ylab}\hlstd{(}\hlkwd{expression}\hlstd{(theta[}\hlnum{2}\hlstd{]))}
\end{alltt}
\end{kframe}
\includegraphics[width=0.5\linewidth]{figure/mv-plot_r_emp-1} 
\end{knitrout}

\item $\frac{\partial}{\partial \bm{\theta}}\mathcal{R}_{\text{emp}} = \sum^n_{i=1} \frac{\exp(\bm{\theta}^\top \mathbf{x}^{(i)})}{1 + \exp(\bm{\theta}^\top \mathbf{x}^{(i)})}{\mathbf{x}^{(i)}}^\top - y^{(i)}{\mathbf{x}^{(i)}}^\top$ 
\item 

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(gridExtra)}

\hlstd{plot_fun} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{gd_fun}\hlstd{,} \hlkwc{lambda}\hlstd{)\{}
  \hlstd{theta} \hlkwb{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{0}\hlstd{)}
  \hlstd{thetas} \hlkwb{=} \hlkwa{NULL}
  \hlstd{thetas_norm} \hlkwb{=} \hlkwa{NULL}
  \hlstd{fs} \hlkwb{=} \hlkwa{NULL}
  \hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{500}\hlstd{)\{}
    \hlstd{theta} \hlkwb{=} \hlkwd{gd_fun}\hlstd{(theta)}
    \hlstd{thetas_norm} \hlkwb{=} \hlkwd{rbind}\hlstd{(thetas_norm,} \hlkwd{sqrt}\hlstd{(theta} \hlopt{%*%} \hlstd{theta))}
    \hlstd{thetas} \hlkwb{=} \hlkwd{rbind}\hlstd{(thetas, theta)}
    \hlstd{fs} \hlkwb{=} \hlkwd{rbind}\hlstd{(fs,} \hlkwd{f}\hlstd{(theta, lambda))}
  \hlstd{\}}

  \hlstd{df_trace} \hlkwb{=} \hlkwd{as.data.frame}\hlstd{(thetas)}
  \hlstd{trace_plot} \hlkwb{=} \hlkwd{ggplot}\hlstd{()} \hlopt{+}
    \hlkwd{geom_line}\hlstd{(}\hlkwc{data} \hlstd{= df_trace,} \hlkwd{aes}\hlstd{(}\hlkwc{x}\hlstd{=V1,} \hlkwc{y}\hlstd{=V2))} \hlopt{+}
    \hlkwd{xlab}\hlstd{(}\hlkwd{expression}\hlstd{(theta[}\hlnum{1}\hlstd{]))} \hlopt{+}
    \hlkwd{ylab}\hlstd{(}\hlkwd{expression}\hlstd{(theta[}\hlnum{2}\hlstd{]))} \hlopt{+}
    \hlkwd{geom_point}\hlstd{(}\hlkwc{data} \hlstd{=} \hlkwd{tail}\hlstd{(df_trace),} \hlkwd{aes}\hlstd{(}\hlkwc{x}\hlstd{=V1,} \hlkwc{y}\hlstd{=V2))}
  \hlstd{norm_plot} \hlkwb{=} \hlkwd{ggplot}\hlstd{(}\hlkwd{data.frame}\hlstd{(}\hlkwc{norms} \hlstd{= thetas_norm,} \hlkwc{t} \hlstd{=} \hlnum{1}\hlopt{:}\hlkwd{nrow}\hlstd{(thetas_norm)))} \hlopt{+}
    \hlkwd{geom_line}\hlstd{(}\hlkwd{aes}\hlstd{(}\hlkwc{x} \hlstd{= t,} \hlkwc{y} \hlstd{= norms))} \hlopt{+} \hlkwd{ylab}\hlstd{(}\hlkwd{expression}\hlstd{(}\hlkwd{paste}\hlstd{(}\hlstr{"||"}\hlstd{, theta,} \hlstr{"||"}\hlstd{[}\hlnum{2}\hlstd{])))}
  \hlstd{remp_plot} \hlkwb{=} \hlkwd{ggplot}\hlstd{(}\hlkwd{data.frame}\hlstd{(}\hlkwc{f} \hlstd{= fs,} \hlkwc{t} \hlstd{=} \hlnum{1}\hlopt{:}\hlkwd{nrow}\hlstd{(thetas_norm)))} \hlopt{+}
    \hlkwd{geom_line}\hlstd{(}\hlkwd{aes}\hlstd{(}\hlkwc{x} \hlstd{= t,} \hlkwc{y} \hlstd{= f))} \hlopt{+} \hlkwd{ylab}\hlstd{(}\hlkwd{expression}\hlstd{(R[emp]))}
  \hlkwd{grid.arrange}\hlstd{(trace_plot, norm_plot, remp_plot,} \hlkwc{ncol}\hlstd{=}\hlnum{3}\hlstd{)}
\hlstd{\}}

\hlstd{df_t} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{,} \hlkwc{lambda}\hlstd{) lambda} \hlopt{*} \hlkwd{t}\hlstd{(theta)} \hlopt{-}\hlstd{(}\hlkwd{t}\hlstd{(y)} \hlopt{%*%} \hlstd{X)} \hlopt{+}
  \hlkwd{t}\hlstd{(}\hlnum{1}\hlopt{/}\hlstd{(}\hlnum{1} \hlopt{+} \hlkwd{exp}\hlstd{(}\hlopt{-}\hlstd{X} \hlopt{%*%} \hlstd{theta)))} \hlopt{%*%} \hlstd{X}

\hlstd{gd_step} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{,} \hlkwc{alpha}\hlstd{,} \hlkwc{lambda}\hlstd{)} \hlkwd{return}\hlstd{(theta} \hlopt{-} \hlstd{alpha} \hlopt{*} \hlkwd{df_t}\hlstd{(theta, lambda)[}\hlnum{1}\hlstd{,])}

\hlcom{## Alpha = 0.01}
\hlstd{gd_fun} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{)} \hlkwd{return}\hlstd{(}\hlkwd{gd_step}\hlstd{(theta,} \hlnum{0.01}\hlstd{, lambda))}
\hlkwd{plot_fun}\hlstd{(gd_fun,} \hlnum{0}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=0.5\linewidth]{figure/mv-plot_gd_step-1} 
\begin{kframe}\begin{alltt}
\hlcom{## Alpha = 0.02}
\hlstd{gd_fun} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{)} \hlkwd{return}\hlstd{(}\hlkwd{gd_step}\hlstd{(theta,} \hlnum{0.02}\hlstd{, lambda))}
\hlkwd{plot_fun}\hlstd{(gd_fun,} \hlnum{0}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=0.5\linewidth]{figure/mv-plot_gd_step-2} 
\end{knitrout}

Gradient descent will in theory not converge since $\mathcal{R}_\text{emp}$ has no minimum (a)
\item

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Lambda = 1, alpha = 0.01}
\hlstd{gd_fun} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{)} \hlkwd{return}\hlstd{(}\hlkwd{gd_step}\hlstd{(theta,} \hlnum{0.01}\hlstd{,} \hlnum{1}\hlstd{))}
\hlkwd{plot_fun}\hlstd{(gd_fun,} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=0.5\linewidth]{figure/mv-plot_gd_step_reg-1} 
\begin{kframe}\begin{alltt}
\hlcom{## Lambda = 1, alpha = 0.02}
\hlstd{gd_fun} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{)} \hlkwd{return}\hlstd{(}\hlkwd{gd_step}\hlstd{(theta,} \hlnum{0.02}\hlstd{,} \hlnum{1}\hlstd{))}
\hlkwd{plot_fun}\hlstd{(gd_fun,} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=0.5\linewidth]{figure/mv-plot_gd_step_reg-2} 
\end{knitrout}

\item 
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{lambda} \hlkwb{=} \hlnum{1}

\hlstd{fxx_reg} \hlkwb{=} \hlkwd{log}\hlstd{(}\hlkwd{apply}\hlstd{(xx,} \hlnum{1}\hlstd{,} \hlkwa{function}\hlstd{(}\hlkwc{t}\hlstd{)} \hlkwd{f}\hlstd{(t, lambda)))}
\hlstd{df_reg} \hlkwb{=} \hlkwd{data.frame}\hlstd{(}\hlkwc{xx} \hlstd{= xx,} \hlkwc{fxx} \hlstd{= fxx_reg)}

\hlkwd{ggplot}\hlstd{()} \hlopt{+}
    \hlkwd{geom_contour_filled}\hlstd{(}\hlkwc{data} \hlstd{= df_reg,} \hlkwd{aes}\hlstd{(}\hlkwc{x} \hlstd{= xx.X1,} \hlkwc{y} \hlstd{= xx.X2,} \hlkwc{z} \hlstd{= fxx))} \hlopt{+}
    \hlkwd{xlab}\hlstd{(}\hlkwd{expression}\hlstd{(theta[}\hlnum{1}\hlstd{]))} \hlopt{+}
    \hlkwd{ylab}\hlstd{(}\hlkwd{expression}\hlstd{(theta[}\hlnum{2}\hlstd{]))}
\end{alltt}
\end{kframe}
\includegraphics[width=0.5\linewidth]{figure/mv-plot_r_emp_reg-1} 
\end{knitrout}
\item
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{gd_backtracking_step} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{,} \hlkwc{alpha}\hlstd{,} \hlkwc{gamma}\hlstd{,} \hlkwc{tau}\hlstd{,} \hlkwc{lambda}\hlstd{)\{}
    \hlstd{ftheta} \hlkwb{=} \hlkwd{f}\hlstd{(theta, lambda)}
    \hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{1000}\hlstd{)\{}
      \hlstd{theta_prop} \hlkwb{=} \hlstd{theta} \hlopt{-} \hlstd{alpha} \hlopt{*} \hlstd{gamma} \hlopt{*} \hlkwd{df_t}\hlstd{(theta, lambda)[}\hlnum{1}\hlstd{,]}
      \hlkwa{if}\hlstd{(}\hlkwd{f}\hlstd{(theta_prop, lambda)} \hlopt{<} \hlstd{ftheta)\{}
        \hlkwd{return}\hlstd{(theta_prop)}
      \hlstd{\}}\hlkwa{else}\hlstd{\{}
        \hlstd{alpha} \hlkwb{=} \hlstd{tau} \hlopt{*} \hlstd{alpha}
      \hlstd{\}}
    \hlstd{\}}
    \hlkwd{return}\hlstd{(theta)}
\hlstd{\}}

\hlcom{## Lambda = 1, alpha = 0.01}
\hlstd{gd_fun} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{)} \hlkwd{return}\hlstd{(}\hlkwd{gd_backtracking_step}\hlstd{(theta,} \hlnum{0.01}\hlstd{,} \hlnum{0.9}\hlstd{,} \hlnum{0.5}\hlstd{,} \hlnum{1}\hlstd{))}
\hlkwd{plot_fun}\hlstd{(gd_fun,} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=0.5\linewidth]{figure/mv-plot_gd_backtrack-1} 
\begin{kframe}\begin{alltt}
\hlcom{## Lambda = 1, alpha = 0.02}
\hlstd{gd_fun} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{theta}\hlstd{)} \hlkwd{return}\hlstd{(}\hlkwd{gd_backtracking_step}\hlstd{(theta,} \hlnum{0.02}\hlstd{,} \hlnum{0.9}\hlstd{,} \hlnum{0.5}\hlstd{,} \hlnum{1}\hlstd{))}
\hlkwd{plot_fun}\hlstd{(gd_fun,} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=0.5\linewidth]{figure/mv-plot_gd_backtrack-2} 
\end{knitrout}
\end{enumerate}
}
\end{document}
