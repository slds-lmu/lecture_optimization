\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}

\title{Optimization in Machine Learning}

\begin{document}

\titlemeta{
Evolutionary Algorithms
}{
CMA-ES Algorithm
}{
figure_man/cmaes/cmaes_generations.png
}{
\item CMA-ES strategy
\item Estimation of distribution
\item Step size control
}

\begin{framev}[align=top]{Estimation of Distribution Algorithm}
\splitVCC[0.62]{
Instead of population, maintain distribution to sample offspring from
\spacer
\begin{enumerate}
\item Draw $\lambda$ offspring $\xv^{(i)}$ from $p(\cdot|\thetav^{[t]})$
\item Evaluate fitness $f(\xv^{(i)})$
\item Update $\thetav^{[t+1]}$ with $\mu$ best offspring
\end{enumerate}
}{
\imageC[1]{figure_man/cmaes/cmaes_eda.png}
}
\end{framev}


\begin{framei}[fs=footnotesize]{Covariance Matrix Adaptation}
\item Sample distribution is multivariate Gaussian
$$
\xv^{[t+1](i)} \sim \mathbf{m}^{[t]} + \sigma^{[t]} \normal(\bm{0}, \mathbf{C}^{[t]}) \quad \text{for } i = 1, \dots, \lambda
$$
\item $\xv^{[t+1](i)} \in \R^d$ $i$-th offspring; $\lambda \geq 2$ number of offspring
\item $\mathbf{m}^{[t]} \in \R^d$ mean value and $\mathbf{C}^{[t]} \in \R^{d \times d}$ covariance matrix
\item $\sigma^{[t]} \in \R_+$ ``overall'' standard deviation/step size
\imageC[0.65]{figure_man/cmaes/cmaes_generations.png}
\item \textbf{Question:} How to adapt $\mathbf{m}^{[t+1]}$, $\mathbf{C}^{[t+1]}$, $\sigma^{[t+1]}$ for next generation $t+1$?
\end{framei}


\begin{framev}[fs=small]{CMA-ES: Basic Method - Iteration 1}
\begin{enumerate} \setcounter{enumi}{-1}
\item Initialize $\mathbf{m}^{[0]},\sigma^{[0]}$ problem-dependent and $\mathbf{C}^{[0]}=\mathbf{I}_{d}$
\imageC[0.85]{figure_man/cmaes/cmaes_update_1.png}
\end{enumerate}
\end{framev}


\begin{framev}[fs=small]{CMA-ES: Basic Method - Iteration 1}
\begin{enumerate} \setcounter{enumi}{0}
\item \textbf{Sample} $\lambda$ offspring from distribution
$$
\xv^{[1](i)} = \mathbf{m}^{[0]} + \sigma^{[0]} \normal(\bm{0}, \mathbf{C}^{[0]})
$$
\imageC[0.85]{figure_man/cmaes/cmaes_update_2.png}
\end{enumerate}
\end{framev}


\begin{framev}[fs=small]{CMA-ES: Basic Method - Iteration 1}
\begin{enumerate} \setcounter{enumi}{1}
\item \textbf{Selection and recombination} of $\mu<\lambda$ best-performing offspring using fixed weights $w_1\geq\ldots\geq w_{\mu}>0,\sum_{i=1}^{\mu} w_i = 1$.
$\xv_{i:\lambda}$ is $i$-th ranked solution, ranked by $f(\xv_{i:\lambda})$.
\imageC[0.85]{figure_man/cmaes/cmaes_update_21.png}
Calculation of auxiliary variables ($\mu=3$ points) $\yv_w^{[1]} := \sum_{i=1}^{\mu} w_i (\xv_{i:\lambda}^{[1]}-\mathbf{m}^{[0]})/\sigma^{[0]} := \sum_{i=1}^{\mu} w_i \yv_{i:\lambda}^{[1]}$
\end{enumerate}
\end{framev}


\begin{framev}[fs=small]{CMA-ES: Basic Method - Iteration 1}
\begin{enumerate} \setcounter{enumi}{2}
\item \textbf{Update mean}
\imageC[0.85]{figure_man/cmaes/cmaes_update_3.png}
Movement towards the new distribution with mean
$\mathbf{m}^{[1]} = \mathbf{m}^{[0]} + \sigma^{[0]} \yv_{w}^{[1]}$.
\end{enumerate}
\end{framev}


\begin{framev}[fs=small]{CMA-ES: Basic Method - Iteration 1}
\begin{enumerate} \setcounter{enumi}{3}
\item \textbf{Update covariance matrix}\\
Roughly: elongate density ellipsoid in direction of successful steps.
$\mathbf{C}^{[1]}$ reproduces successful points with higher probability than $\mathbf{C}^{[0]}$.
\imageC[0.85]{figure_man/cmaes/cmaes_update_4.png}
\begin{small}
Update $\mathbf{C}^{[0]}$ using sum of outer products and parameter $c_{\mu}$:
$\mathbf{C}^{[1]} = (1-c_{\mu}) \mathbf{C}^{[0]} + c_{\mu} \sum_{i=1}^{\mu} w_i \yv_{i:\lambda}^{[1]}(\yv_{i:\lambda}^{[1]})^T$ (rank-$\mu$ update).
\end{small}
\end{enumerate}
\end{framev}


\begin{framev}[fs=small]{CMA-ES: Basic Method - Iteration 2}
\begin{enumerate}
\item \textbf{Sample} from distribution for new generation
\imageC[0.85]{figure_man/cmaes/cmaes_update_5.png}
\end{enumerate}
\end{framev}


\begin{framev}[fs=small]{CMA-ES: Basic Method - Iteration 2}
\begin{enumerate} \setcounter{enumi}{1}
\item \textbf{Selection and recombination} of $\mu<\lambda$ best-performing offspring
\item \textbf{Update mean}
\imageC[0.85]{figure_man/cmaes/cmaes_update_6.png}
\end{enumerate}
\end{framev}


\begin{framev}[fs=small]{CMA-ES: Basic Method - Iteration 2}
\begin{enumerate}\setcounter{enumi}{1}
\item \textbf{Update covariance matrix}
\imageC[0.85]{figure_man/cmaes/cmaes_update_7.png}
\end{enumerate}
\end{framev}


\begin{framev}[fs=small]{CMA-ES: Basic Method - Iteration 2}
\begin{enumerate}\setcounter{enumi}{1}
\item \textbf{Update step-size} exploiting correlation in history of steps.\\
steps point in similar direction $\implies$ increase step-size
steps cancel out $\implies$ decrease step-size
\imageC[0.85]{figure_man/cmaes/cmaes_update_8.png}
\end{enumerate}
\end{framev}


\begin{framev}[fs=small]{Updating $\mathbf{C}$: Full Update}
Full CMA update of $\mathbf{C}$ combines rank-$\mu$ update with a rank-$1$ update using exponentially smoothed evolution path $\mathbf{p}_c \in \R^{d}$ of successive steps and learning rate $c_1$:
$$
\mathbf{p}_{c}^{[0]}=\bm{0}, \quad \mathbf{p}_{c}^{[t+1]} = (1-c_1)\mathbf{p}_{c}^{[t]} + \sqrt{\frac{c_1(2-c_1)}{\sum_{i=1}^{\mu}w_i^2}}\yv_w
$$
Final update of $\mathbf{C}$ is
$$
\mathbf{C}^{[t+1]}=(1-c_1-c_{\mu}{\scriptstyle\sum_j} w_j)\mathbf{C}^{[t]}+c_1 \underbrace{\mathbf{p}_{c}^{[t+1]}(\mathbf{p}_{c}^{[t+1]})^T}_{\text{rank-$1$}}+c_{\mu}\underbrace{\sum_{i=1}^{\mu}w_i \yv_{i:\lambda}^{[t+1]}(\yv_{i:\lambda}^{[t+1]})^T}_{\text{rank-$\mu$}}
$$
\begin{itemize}
\item Correlation between generations used in rank-$1$ update
\item Information from entire population is used in rank-$\mu$ update
\end{itemize}
\end{framev}


\begin{framei}[sep=L, fs=small]{Updating $\sigma$: Methods Step-Size Control}
\item \textbf{$1/5$-th success rule}: increases the step-size if more than 20 \% of the new solutions are successful, decrease otherwise
\item \textbf{$\sigma$-self-adaptation}: mutation is applied to the step-size and the better - according to the objective function value - is selected
\item \textbf{Path length control via cumulative step-size adaptation (CSA)}\\ Intuition:
\begin{itemizeS}
\item Short cumulative step-size $\triangleq$ steps cancel $\to$ decrease $\sigma^{[t+1]}$
\item Long cumulative step-size $\triangleq$ corr. steps $\to$ increase $\sigma^{[t+1]}$
\end{itemizeS}
\vfill
\imageC[0.8]{figure_man/cmaes/cumulative-step-size.png}
\end{framei}

\endlecture
\end{document}
