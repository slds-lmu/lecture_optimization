\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}

\newcommand{\xleft}{x_{\text{left}}} 
\newcommand{\xright}{x_{\text{right}}} 
\newcommand{\xnew}{x_{\text{new}}} 
\newcommand{\xbest}{x_{\text{best}}} 
\newcommand{\fleft}{f_{\text{left}}} 
\newcommand{\fright}{f_{\text{right}}} 
\newcommand{\fnew}{f_{\text{new}}} 
\newcommand{\fbest}{f_{\text{best}}} 
\newcommand{\xii}{x^{(i)}} 

\title{Optimization in Machine Learning}

\begin{document}

\titlemeta{
Univariate optimization
}{
Brent's method
}{
figure_man/quadratic-title.png
}{
\item Quadratic interpolation
\item Brent's procedure
}

\begin{frame}{Quadratic Interpolation}
Similar to golden ratio procedure but select $\xnew$ differently: $\xnew$ as minimum of fitted parabola through 
$$(\xleft, \fleft), (\xbest, \fbest), (\xright, \fright)$$ 
\foreach \i in {1, 2, 3, 4, 5}{
\only<\i>{
\image{figure_man/quadratic\i.pdf}
Left: Fit parabola (dashed) and propose minimum (red) as new point. Middle: Switch / not switch with $\xbest$. Right: New interval. 
}}
\end{frame}

\begin{framei}[sep=L]{Quadratic interpolation comments}
\item Quadratic interpolation \textbf{not robust}. The following may happen:
\begin{itemizeL}
\item Algorithm suggests same $\xnew$ in each step
\item $\xnew$ outside of search interval
\item Parabola degenerates to line and no real minimum exists 
\end{itemizeL}
\item Algorithm must then abort, finding a global minimum is not guaranteed
\end{framei}

\begin{framei}[sep=L]{Brent's method}
\item Brent's algorithm \furtherreading{BRENT1973} alternates between golden ratio search and quadratic interpolation as follows: 
\begin{itemizeM}
\item Quadratic interpolation step acceptable if:\\ 
(i) $\xnew$ falls within $[\xleft, \xright]$\\ 
(ii) $\xnew$ sufficiently far away from  $\xbest$ \\
{\footnotesize (Heuristic: Less than half of the movement of step before last)} 
\item Otherwise: proposal via golden ratio
\end{itemizeM}
\item Benefit: fast convergence (quadratic interpolation), unstable steps stabilized by golden ratio search
\item Convergence guaranteed if function $f$ has local min
\item Used in R-function \texttt{optimize()}
\end{framei}


\begin{framei}{Example: MLE Poisson}
\item Poisson density: $f(k|\lambda) := \P(x = k) = \frac{\lambda^k \cdot \exp(-\lambda)}{k!}$
\item Negative log-likelihood for $n$ samples:
\begin{equation*}
- \ell(\lambda, \mathcal{D}) = - \log \prodin  f(\xii | \lambda) =  - \sumin \log f(\xii | \lambda) 
\end{equation*}
\imageC[0.7]{figure_man/poisson.pdf}
GR and Brent converge to global min at $x^\ast \approx 1$ \\
But GR needs $\approx 45$ iters, Brent only $\approx 15$ for same tolerance
\end{framei}

\endlecture

\end{document}