\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\input{../../style/preamble}\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}

\newcommand{\xleft}{x_{\text{left}}} 
\newcommand{\xright}{x_{\text{right}}} 
\newcommand{\xnew}{x_{\text{new}}} 
\newcommand{\xbest}{x_{\text{best}}} 

\usepackage{textpos}

\title{Optimization in Machine Learning}

\begin{document}

\titlemeta{
Univariate optimization
}{
Golden ratio
}{
figure_man/golden-ratio-6.png
}{
\item Simple nesting procedure
\item Golden ratio 
}

\begin{frame2}{univariate Optimization}
Let $f: \R \to \R$ (search over interval $(\xleft,\xright)$ in practice)\\
\lz 
\textbf{Goal}: Iteratively improve eval points. Assume function $-f$ is unimodal. Will not rely on gradients, so this also works for black-box problems.
\imageC{figure_man/golden-ratio-0.png}
\end{frame2}

\begin{frame}{simple nesting procedure}
Let $f: \R \to \R$\\
\lz 
\only<1>{
Always maintain three points: left, right, and current best
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-1.png}
\end{textblock*}
}
\only<2>{
Propose random interval point (def. optimal new proposal later)
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-2.png}
\end{textblock*} 
}
\only<3>{
Compare proposal against current best
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-3.png}
\end{textblock*} 
}
\only<4>{
If it is better: proposal becomes current best
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-4.png}
\end{textblock*} 
}
\only<5>{
New search interval: around current best 
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-5.png}
\end{textblock*} 
}
\only<6>{
Propose a random point  
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-6.png}
\end{textblock*} 
}
\only<7>{
Compare proposal against current best
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-7.png}
\end{textblock*} 
}
\only<8>{
If it is better: proposal becomes current best
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-8.png}
\end{textblock*} 
}
\only<9>{
New search interval: around current best
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-9.png}
\end{textblock*} 
}
\only<10>{
Propose a random point
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-10.png}
\end{textblock*} 
}
\only<11>{
Compare proposal against current best 
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-11.png}
\end{textblock*} 
}
\only<12>{
If it is better: proposal becomes current best
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-12.png}
\end{textblock*} 
}
\only<13>{
New search interval: around current best
\begin{textblock*}{\linewidth}(0cm,0cm) 
\image[1]{figure_man/golden-ratio-13.png}
\end{textblock*} 
}
\end{frame}

\begin{framei}{simple nesting procedure}
\item Initialization: Search interval  $(\xleft, \xright)$, $\xleft < \xright$
\item Choose $\xbest$ randomly
\item For $t = 0, 1, 2, ...$
\begin{itemize}
\item Choose $\xnew$ randomly in $[\xleft, \xright]$
\item If $f(\xnew) < f(\xbest)$:
\begin{itemize}
\item $\xbest \leftarrow \xnew$
\end{itemize}
\item New interval: points around $\xbest$
\end{itemize}
\image{figure_man/golden-ratio-summary.png}
\end{framei}

\begin{frame2}{golden ratio}
Key question: How can $\xnew$ be chosen better than randomly? 
\begin{itemizeM}
\item Insight 1: Always in bigger subinterval to maximize reduction
\item Insight 2: $\xnew$ symmetrically to $\xbest$ for uniform reduction
\end{itemizeM}
\imageC[1.0]{figure_man/goldensec-0.png}
\vspace{-1cm}
Consider two hypothetical outcomes for $\xnew$: $f_{new, a}$ and $f_{new, b}$
\end{frame2}

\begin{frame2}{golden ratio}
If outcome is $f_{new, a}$, $\xbest$ remains best and we search around $\xbest$: $$[\xleft, \xnew]$$
\vfill
\imageC[1.0]{figure_man/goldensec-1.png}
\end{frame2}

\begin{frame2}{golden ratio}
If $f_{new, b}$ is outcome, $\xnew$ becomes best point and search around $\xnew$: $$[\xbest, \xright]$$
\vfill
\imageC[1.0]{figure_man/goldensec-3.png}
\end{frame2}

\begin{frame2}{golden ratio}
For uniform reduction the two potential intervals must be equal-sized: 
\begin{equation*}
b := \xright - \xbest = \xnew - \xleft
\end{equation*}
\vfill
\imageC[1.0]{figure_man/goldensec-3.png}
\end{frame2}

\begin{frame2}{golden ratio}
One iteration ahead: require again the intervals to be of same size. 
$$c := \xbest - \xleft = \xright - \xnew$$
\vfill
\imageC[1.0]{figure_man/goldensec-4.png}
\end{frame2}

\begin{frame2}{golden ratio}
To summarize, we require: 
\begin{eqnarray*}
a &=& \xright-\xleft, \\
b &=& \xright - \xbest = \xnew - \xleft \\
c &=& \xbest - \xleft = \xright - \xnew
\end{eqnarray*}
\vfill
\imageC[0.5]{figure_man/goldensec.png}
\end{frame2}

\begin{framei}{golden ratio}
\item We require same percentage improvement in each iteration
\item For $\varphi$ reduction factor of interval sizes ($a$ to $b$, and $b$ to $c$)
$$\varphi := \frac{b}{a} = \frac{c}{b}$$
$$\varphi^2 = \frac{b}{a} \cdot \frac{c}{b} = \frac{c}{a}$$
\item Divide $a = b + c$ by $a$:
\begin{eqnarray*}
\frac{a}{a} &=& \frac{b}{a} + \frac{c}{a} \\
1 &=& \varphi + \varphi^2 \\
0 &=& \varphi^2 + \varphi - 1
\end{eqnarray*}
\item Unique positive solution is $\varphi = \frac{\sqrt{5}-1}{2} \approx 0.618$
\end{framei}

\begin{framei}[fs=normalsize,sep=L]{golden ratio}
\item With $\xnew$ we always go $\varphi$ percentage points into the interval
\item Given $\xleft$ and $\xright$ it follows
\begin{eqnarray*}
\xbest&=&\xright-\varphi(\xright-\xleft)\\
&=&\xleft+(1-\varphi)(\xright-\xleft)
\end{eqnarray*}
and due to symmetry
\begin{eqnarray*}
\xnew&=& \xleft+\varphi(\xright-\xleft)\\ &=& \xright-(1-\varphi)(\xright-\xleft).
\end{eqnarray*}
\end{framei}

\begin{framei}[sep=L]{golden ratio}
\item Some termination criterion has to be chosen 
\item A reasonable choice is the absolute error, i.e. the width of the last interval:
$$|\xbest-\xnew| < \tau$$
\item In practice, more complicated termination criteria are usually applied, e.g. \emph{Numerical Recipes in C} \furtherreading{TEUCH92} proposes
$$|\xright-\xleft| \le \tau (|\xbest| + |\xnew|)$$
as a termination criterion
% (Schranke für Breite des Suchintervalls in Abhängigkeit der Größenordnung des Minimums):
% $$
% |\xright-\xleft| < \tau(1+|\xbest|)
% $$
\end{framei}

\endlecture

\end{document}


