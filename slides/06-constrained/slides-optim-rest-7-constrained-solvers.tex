\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}


\newcommand{\titlefigure}{figure_man/convex_programs.png}
\newcommand{\learninggoals}{
\item Definition
\item Max. Likelihood 
\item Normal regression
\item Risk Minimization
}


%\usepackage{animate} % only use if you want the animation for Taylor2D

\title{Optimization in Machine Learning}
%\author{Bernd Bischl}
\date{}

\begin{document}

\lecturechapter{Nonlinear programs: Solvers}
\lecture{\inserttitle}
\sloppy
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{vbframe}{Sequential quadratic programming}

For simplification, we consider only equality constraints, thus problems of the form

$$
\min f(\xv) \qquad \text{s.t. } \quad h(\xv) = 0.
$$

\textbf{Idea:}

\begin{itemize}
\item Instead of $f$ we optimize the 2nd order Taylor approximation in a point $\bm{\tilde x}$

$$
\tilde f(\xv) = f(\bm{\tilde x}) +  \nabla_{x} f(\bm{\tilde x})^T (\xv- \bm{\tilde x})+ \frac{1}{2} (\xv- \bm{\tilde x})^T \nabla^2_{xx} f(\bm{\tilde x}) (\xv- \bm{\tilde x})
$$

\item $h$ is also replaced by its linear approximation in $\bm{\tilde x}$.

$$
\tilde h(\xv) = h(\bm{\tilde x}) + \nabla h(\bm{\tilde x})^T(\xv- \bm{\tilde x}).
$$
\end{itemize}

\framebreak

With $\bm{d} := (\xv- \bm{\tilde x})$ we formulate the \textbf{quadratic auxiliary problem}

\begin{eqnarray*}
\min_{\bm{d}} && \tilde f(\bm{d}) := f(\bm{\tilde x}) + \bm{d}^T \nabla_{x} f(\bm{\tilde x}) + \frac{1}{2} \bm{d}^T \nabla^2_{xx} f(\bm{\tilde x}) \bm{d} \\
\text{s.t. } && \tilde h(\bm{d}) :=  h(\bm{\tilde x}) + \nabla h(\bm{\tilde x})^T\bm{d} = 0.
\end{eqnarray*}

Even if no conditions for optimality can be formulated for the actual optimization problem, the KKT conditions apply in an optimum of this problem necessarily.

\lz

If the matrix $\nabla^2_{xx} f(\xv)$ is positive semidefinite, it is a \textbf{convex optimization problem}.

\framebreak

Using the Lagrange function

$$
L(\bm{d}, \bm{\beta}) = \bm{d}^T \nabla_{x} f(\bm{\tilde x}) + \frac{1}{2} \bm{d}^T \nabla^2_{xx} f(\bm{\tilde x}) \bm{d} + \bm{\beta}^T (h(\bm{\tilde x}) + \nabla h(\bm{\tilde x})^T\bm{d})
$$

we formulate the KKT conditions

\begin{itemize}
\item $\nabla_{\bm{d}} L(\bm{d}, \bm{\beta}) = \nabla_{x} f(\bm{\tilde x}) + \nabla^2_{xx} f(\bm{\tilde x}) \bm{d} + \nabla h(\bm{\tilde x})^T\bm{\beta} = 0$
\item $h(\bm{\tilde x}) + \nabla h(\bm{\tilde x})^T\bm{d} = 0$
\end{itemize}

or in matrix notation

$$
\begin{pmatrix} \nabla^2_{xx} f(\bm{\tilde x}) & \nabla h(\bm{\tilde x})^T \\ \nabla h(\bm{\tilde x}) & 0 \end{pmatrix} \begin{pmatrix} \bm{d} \\ \bm{\beta} \end{pmatrix} = - \begin{pmatrix} \nabla_{x} f(\bm{\tilde x}) \\ h(\bm{\tilde x}) \end{pmatrix}
$$

The solution of the \textbf{quadratic subproblem} can thus be traced back to the solution of a linear system of equations.


\framebreak

\begin{algorithm}[H]
  \caption{SQP for problems with equality constraints}
  \begin{algorithmic}[1]
  \State Select a feasible starting point $\mathbf{x}^{(0)} \in \R^n$
  \While {Stop criterion not fulfilled}
    \State Solve quadratic subproblem by solving the equation
    $$\begin{pmatrix} \nabla^2_{xx} L(\xv, \bm{\mu}) & \nabla h(\xv)^T \\ \nabla h(\xv) & 0 \end{pmatrix} \begin{pmatrix} \bm{d} \\ \bm{\beta} \end{pmatrix} = - \begin{pmatrix} \nabla_{x} L(\xv, \bm{\mu}) \\ h(\xv) \end{pmatrix}$$
    \State Set $\xv^{(i + 1)} = \xv^{(i)} + \bm{d}$
    % , $\bm{\mu}^{(i + 1)} = \bm{\mu}^{(i)} + \bm{\beta}$
  \EndWhile
  \end{algorithmic}
\end{algorithm}

% \framebreak
%
%
%
% indem die Zielfunktion $f$ mithilfe einer Taylorapproximation 2. Ordnung und die Nebenbedingung mithilfe einer Taylorapproximation 1. Ordnung approximiert wurde.
%
% \framebreak
%
% Die KKT-Bedingungen sind für lineare Nebenbedingungen immer notwendig und lauten
%
%   \begin{itemize}
%     \item $\nabla L(\xv, \bm{\beta}) = 0$ (Stationarität der Lagrange-Funktion),
%     \item $h(\xv) = 0$ (primale Zulässigkeit),
%   \end{itemize}
%
% wobei
%
% $$
% L(\bm{d}, \bm{\beta}) = \bm{d}^T \nabla_{x} L(\xv, \bm{\mu}) + \frac{1}{2} \bm{d}^T \nabla^2_{xx} L(\xv, \bm{\mu}) \bm{d} + \bm{\beta}^T (h(\xv) + \nabla h(\xv)bm{d})
% $$
%
%
% \lz
%
% \textbf{Idee:} Finde KKT-Paar $(\xv, \bm{\beta})$
%
% $$
% F(\xv, \bm{\beta}) := \begin{pmatrix} \nabla_x L(\xv, \bm{\beta}) \\ h(\xv) \end{pmatrix} = 0
% $$
%
% mithilfe des (multivariaten) Newton-Verfahrens.
%
% \framebreak
%
% % \begin{footnotesize}
% % Das \textbf{Multivariate Newton-Verfahren} für Nullstellensuche lässt sich auf ähnliche Weise wie das univariate herleiten. Die Updates für eine Funktion $f:\R^n \to \R$ lauten:
% %
% % \begin{eqnarray*}
% % && \xv^{(n + 1)} = \xv^{(n)} + \bm{d}^{(n)}, \\
% % \text{wobei} &&  \bm{d}^{(n)} \text{ so gewählt, dass } \nabla f(\xv^{(n)})^T  \bm{d}^{(n)} = - f(\xv^{(n)})
% % \end{eqnarray*}
% % \end{footnotesize}
%
% \lz
%
% Wir lösen also in jeder Iteration die sog. \textbf{Lagrange-Newton-Gleichung} (i.d.R. mihilfe einer gängigen Matrixzerlegung)
%
% $$
% \begin{pmatrix} \nabla^2_{xx} L(\xv, \bm{\mu}) & \nabla h(\xv)^T \\ \nabla h(\xv) & 0 \end{pmatrix} \begin{pmatrix} \bm{d} \\ \bm{\beta} \end{pmatrix} = - \begin{pmatrix} \nabla_{x} L(\xv, \bm{\mu}) \\ h(\xv) \end{pmatrix}.
% $$
%
% Dieselbe Gleichung erhalten wir aber auch, wenn wir das KKT-System des \textbf{quadratischen Optimierungsproblems}
%
% \begin{eqnarray*}
% \min_{\bm{d}} && \bm{d}^T \nabla_{x} L(\xv, \bm{\mu}) + \frac{1}{2} \bm{d}^T \nabla^2_{xx} L(\xv, \bm{\mu}) \bm{d} \\
% \text{u.d.N. } && h(\xv) + \nabla h(\xv)bm{d} = 0
% \end{eqnarray*}
%
% betrachten. In jedem Newton-Schritt wird sozusagen das quadratische Problem gelöst, das man erhält, wenn man die Funktionen $f, h$ durch ihre Taylorapproximation ersetzt!
%
% \framebreak
%
% \begin{footnotesize}
%
% \textbf{Äquivalenz der beiden Probleme:}
%
% Die Lagrange Funktion des quadratischen Problems lautet
%
% $$
% L(\bm{d}, \bm{\beta}) = \bm{d}^T \nabla_{x} L(\xv, \bm{\mu}) + \frac{1}{2} \bm{d}^T \nabla^2_{xx} L(\xv, \bm{\mu}) \bm{d} + \bm{\beta}^T (h(\xv) + \nabla h(\xv)bm{d})
% $$
%
% Die Äquivalenz der Probleme sieht man, wenn man sich die KKT-Bedingungen des quadratischen Problems aufschreibt:
%
% \begin{itemize}
% \item $\nabla_{x} L(\xv, \bm{\mu}) + \nabla^2_{xx} L(\xv, \bm{\mu}) \bm{d} + \nabla h(\xv)bm{d}^T\bm{\beta} = 0$
% \item $\nabla h(\xv)bm{d}\bm{d} + h(\xv = 0$
% \end{itemize}
%
% oder in Matrixschreibweise
%
% $$
% \begin{pmatrix} \nabla^2_{xx} L(\xv, \bm{\mu}) & \nabla h(\xv)^T \\ \nabla h(\xv) & 0 \end{pmatrix} \begin{pmatrix} \bm{d} \\ \bm{\beta} \end{pmatrix} = - \begin{pmatrix} \nabla_{x} L(\xv, \bm{\mu}) \\ h(\xv) \end{pmatrix}.
% $$
%
% \end{footnotesize}

\end{vbframe}

\begin{vbframe}{Penalty methods}

\textbf{Idea:} Replace the constrained Optimization problem with a sequence of unconstrained optimization problems using a \textbf{penalty function}.

\lz

Instead of looking at

$$
\min f(\xv) \qquad \text{s.t. } \quad h(\xv) = 0.
$$

we look at the unconstrained optimization problem

$$
\min_{\xv} p(\xv) = f(\xv) + \rho \frac{\|h(\xv)\|^2}{2}.
$$

Under appropriate conditions it can be shown that the solutions of the problem for $\rho \to \infty$ converge against the solution of the initial problem.

\end{vbframe}

\begin{vbframe}{Barrier method}

\textbf{Idea:} Establish a \enquote{barrier} that penalizes if $\xv$ comes too close to the edge of the allowed set $\bm{S}$. For the problem

$$
\min f(\xv) \qquad \text{s.t. } \quad g(\xv) \le 0
$$

a common \textbf{Barrier function} is

$$
B_\rho = f(\xv) - \rho \sum_{i = 1}^m \ln(-g_i(\xv))
$$

The penalty term becomes larger, the closer $\xv$ comes to $0$, i.e. the limit of the feasible set. Under certain conditions, the solutions of $\min B_\rho$ for $\rho\to 0$ converge against the optimum of the original problem.

\lz

The procedure is also called \textbf{interior-point method}.


\end{vbframe}

% \begin{vbframe}{Support Vector Machines}

% \textbf{Problem: } Binäre Klassifikizierung mithilfe einer Hyperebene

% \lz

% \textbf{Idee:} Bestimme die Hyperebene so, dass der Minimalabstand (\textbf{Margin}) der Punkte zur Hyperebene maximal ist.

%   \begin{center}
% \includegraphics[width=3cm]{figure_man/separable-c2.pdf}~~~\includegraphics[width=3cm]{figure_man/separable-d2.pdf}
% \begin{footnotesize} \\
% Links: Minimalabstand \textbf{nicht} maximal. Rechts: Minimalabstand maximal (SVM-Lösung).
% \end{footnotesize}
%   \end{center}

% \framebreak

% Es bezeichne $\gamma$ den Margin. Gegeben Daten $\{(\xv_1, y_1),  ..., (\xv_n, y_n)\}$ mit binärem Label $y_i \in \{-1, 1\}$ lautet das Optimierungsproblem dann

%   \begin{eqnarray*}
%     & \max\limits_{\theta, \theta_0} & \gamma \\
%     & \text{s.t.} & \,\, y_i \cdot \left(\bm{\theta}^T \xv_i + \theta_0 \right) \ge \gamma \quad \text{für alle } i \in \{1, ..., n\},\\
%     & \qquad & \|\theta\| = 1
%    \end{eqnarray*}


% \end{vbframe}



\section{Constrained Optimization in R}

\begin{vbframe}{Constrained Optimization in R}
\begin{itemize}
\item The function \pkg{optim(..., method = \enquote{L-BFGS-B})} uses quasi-newton methods and can handle box constraints.
\item The function \pkg{nlminb()} uses trust-region procedures and can also handle box constraints.
\item \pkg{constrOptim()} can be used for optimization problems with linear inequality conditions and is based on interior-point methods.
\item \pkg{nloptr} is an interface to \pkg{NLopt}, an open-source library for nonlinear optimization (\url{https://nlopt.readthedocs.io/en/latest/})
\end{itemize}

\end{vbframe}


% \begin{vbframe}{Ganzzahlige Optimierung und Relaxation}

% Wir betrachten ein Problem der ganzzahligen Optimierung, z. B.

% \begin{eqnarray*}
% \min && f(\xv) \\
% && x_i \in \{0, 1\} \text{ für alle } i = 1, ..., n.
% \end{eqnarray*}

% Solche ganzzahligen Optimierungsprobleme sind NP-schwer.

% \lz

% Ersetzen wir die Nebenbedingung des originalen Optimierungsproblems durch die \textbf{lineare} Nebenbedingungen

%  $$
% 0 \le x_i \le 1 \text{ für alle } i = 1, ..., n,
%  $$

% so sprechen wir von \textbf{LP-Relaxation}.

% \framebreak

% Ersetzen wir die Nebenbedingungen durch konvexe Nebenbedingungen, so sprechen wir von \textbf{konvexer Relaxation}.

% \lz

% Von Relaxation im Kontext eines Optimierungsproblems wird allgemein dann gesprochen, wenn die Menge zulässiger Lösungen vergrößert wird.

% \framebreak

% \textbf{Beispielanwendung: } Variablenselektion

% \lz

% \textbf{Ziel: } Finde Optimallösung eines Regressionproblems $\le t$ Variablen

% \vspace*{-0.2cm}
% \begin{eqnarray*}
% \min_{\bm{\beta}} && \frac{1}{n}\sum_{i = 1}^n\left(\bm{y}^{(i)} - \bm{\theta}^T\xv^{(i)}\right)^2 \\
% \text{u.d.N. } && \|\bm{\theta}\|_0 \le t,
% \end{eqnarray*}

% wobei die \enquote{$L_0$-Norm} definiert ist als die Anzahl der Einträge ungleich $0$:

% $$
% \|\bm{\theta}\|_0 = \sum_{i = 1}^n \bm{1}_{\theta_i \ne 0}.
% $$

% \framebreak

% Aufgrund der \enquote{$L_0$-Norm} (Achtung: genaugenommen keine Norm) nicht-konvexes, ganzzahliges Optimierungsproblem (NP-schwer).

% \lz

% Um das Problem dennoch effizient zu lösen, optimieren wir stattdessen die beste konvexe Relaxation

% \begin{eqnarray*}
% \min_{\bm{\beta}} && \frac{1}{n}\sum_{i = 1}^n\left(\bm{y}^{(i)} - \bm{\theta}^T\xv^{(i)}\right)^2 \\
% \text{u.d.N. } && \|\bm{\theta}\|_1 \le t,
% \end{eqnarray*}

% welche unter \textbf{Lasso-Regression} bekannt ist.

% \end{vbframe}





\endlecture
\end{document}



