\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\usepackage{graphicx}


\newcommand{\titlefigure}{figure_man/Taylor2D/Taylor2D_1st100.png}
\newcommand{\learninggoals}{
\item Taylor's theorem (univariate)
\item Taylor series (univariate)
\item Taylor's theorem (multivariate)
\item Taylor series (multivariate)}


%\usepackage{animate} % only use if you want the animation for Taylor2D

\title{Optimization in Machine Learning}
%\author{Bernd Bischl}
\date{}

\begin{document}

\lecturechapter{Mathematical Concepts: \\Taylor Approximations}
\lecture{\inserttitle}
\sloppy


\begin{vbframe}{Taylor approximations}

\begin{itemize}
    \item Mathematically fascinating: \textbf{Globally} approximate function by sum of polynomials determined by \textbf{local} properties
    \item Extremely important for \textbf{analyzing} optimization algorithms
    \item Geometry of \textbf{linear} and \textbf{quadratic} functions very well understood \\ $\implies$ use them for \textbf{approximations}
\end{itemize}

\begin{columns}
\begin{column}{0.45\textwidth}
\includegraphics[width=\columnwidth]{figure_man/taylor_univariate.png}
\end{column}
\begin{column}{0.55\textwidth}
\includegraphics[width=\columnwidth]{figure_man/Taylor2D/Taylor2D_2nd-100.png}
\end{column}
\end{columns}


\end{vbframe}

\begin{vbframe}{Taylor's theorem (univariate)}


\textbf{Taylor's theorem:} Let $I \subseteq \R$ be an open interval and $f \in \mathcal{C}^k(I,\R)$.
For each $a,x \in I$, it holds that
\begin{equation*}
    f(x) = \underbrace{\sum_{j=0}^{k} \frac{f^{(j)}(a)}{j!}(x-a)^{j}}_{T_k(x,a)} + R_k(x,a)
\end{equation*}
with the $k$-th \textbf{Taylor polynomial} $T_{k}$ and a \textbf{remainder term}
\begin{equation*}
    R_k(x, a) = \littleo(|x-a|^k) \quad\textnormal{as~$x \to a$}.
\end{equation*}


\begin{itemize}
    \item There are explicit formulas for the remainder
    \item Wording: We \enquote{expand~$f$ via Taylor around~$a$}
\end{itemize}

\end{vbframe}

\begin{vbframe}{Taylor series (univariate)}

\begin{itemize}
    \item If $f \in C^\infty$, it \textit{might} be expandable around~$a \in I$ as a \textbf{Taylor series}
        \begin{equation*}
            \sum_{k=0}^{\infty} \frac{f^{(k)}(a)}{k!}(x-a)^{k}
        \end{equation*}
    \item If Taylor series converges to~$f$ in an interval~$I_0 \subseteq I$ centered at~$a$ (does not have to), we call~$f$ an \textit{analytic function}
    \item Convergence if $R_k(x, a) \rightarrow 0$ as $k \rightarrow \infty$ for all $x \in I_0$
    \item Then, for all~$x \in I_0$:
        \begin{equation*}
            f(x) = \sum_{j=0}^{\infty} \frac{f^{(j)}(a)}{j!}(x-a)^{j}
        \end{equation*}
\end{itemize}

\end{vbframe}


\begin{vbframe}{Taylor's theorem (multivariate)}

\vspace{-\baselineskip}


\textbf{Taylor's theorem (1st order)}: For $f\in\mathcal{C}^1$, it holds that
\begin{equation*}
    f(\xv) = \underbrace{f(\bm{a}) + \nabla f(\bm{a})^T (\xv - \bm{a})}_{T_1(\xv, \bm{a})} + R_1(\xv,\bm{a}).
\end{equation*}


\begin{footnotesize}
    \textbf{Example: } $\fx = \sin(2x_1) + \cos(x_2)$, $\bm{a} = (1, 1)^T$.
    Since $\nabla \fx = \begin{pmatrix}2\cos(2x_1) \\ -\sin(x_2)\end{pmatrix}$,

    \vspace{-0.7\baselineskip}

    \begin{align*}
        \fx &= T_1(\xv) + R_1(\xv, \bm{a}) = f(\bm{a}) + \nabla f(\bm{a})^T (\xv - \bm{a}) + R_1(\xv, \bm{a})\\
        &= \sin(2) + \cos(1) + (2 \cos(2), - \sin(1))^T\begin{pmatrix} x_1 - 1 \\ x_2 - 1\end{pmatrix} + R_1(\xv, \bm{a})
    \end{align*}
\end{footnotesize}

\vspace*{-0.5\baselineskip}

\begin{columns}
    \begin{column}{0.4\textwidth}
        %   \animategraphics[loop,controls,width=\linewidth]{7}{figure_man/Taylor2D/Taylor2D_1st}{0}{359}
        \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_1st100.png}
    \end{column}
    \begin{column}{0.4\textwidth}
        \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_1st301.png}
    \end{column}
\end{columns}

\framebreak

\vspace*{-1cm}


\textbf{Taylor's theorem (2nd order)}: If $f \in \mathcal{C}^2$, it holds that
\begin{equation*}
    f(\xv) = \underbrace{f(\bm{a}) + \nabla f(\bm{a})^T (\xv - \bm{a}) + \frac{1}{2}(\xv - \bm{a})^T\bm{H}(\bm{a})(\xv - \bm{a})}_{T_2(\xv, \bm{a})} + R_2(\xv,\bm{a})
\end{equation*}


\begin{footnotesize}
    \textbf{Example (continued):} Since $H(\xv) = \begin{pmatrix} -4 \sin(2x_1) & 0 \\ 0 & -\cos(x_2) \end{pmatrix}$,
    \begin{equation*}
        \fx = T_1(\xv, \bm{a}) + \frac{1}{2}\begin{pmatrix}x_1 - 1 \\ x_2 - 1 \end{pmatrix}^T \begin{pmatrix} -4 \sin(2) & 0 \\ 0 & -\cos(1) \end{pmatrix} \begin{pmatrix}x_1 - 1 \\ x_2 - 1 \end{pmatrix} + R_2(\xv, \bm{a})
    \end{equation*}
\end{footnotesize}

\vspace*{-0.5\baselineskip}

\begin{columns}
    \begin{column}{0.4\textwidth}
        %   \animategraphics[loop,controls,width=\linewidth]{7}{figure_man/Taylor2D/Taylor2D_2nd-}{0}{359}
        \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_2nd-100.png}
    \end{column}
    \begin{column}{0.4\textwidth}
        \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_2nd-301.png}
    \end{column}
\end{columns}

\end{vbframe}


\begin{vbframe}{Multivariate Taylor approximation}

\begin{itemize}
    \item Higher order~$k$ gives a better approximation
    \item $T_k(\xv,\bm{a})$ is the best $k$-th order approximation to $\fx$ near $\bm{a}$
\end{itemize}

\begin{columns}
    \begin{column}{0.48\textwidth}
        \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_1st100.png}
    \end{column}
    \begin{column}{0.48\textwidth}
        \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_2nd-100.png}
    \end{column}
\end{columns}

Consider $T_2(\xv, \bm{a}) = f(\bm{a}) + \nabla f(\bm{a})^T (\xv-\bm{a}) + \frac{1}{2}(\xv-\bm{a})^T H (\bm{a})(\xv-\bm{a})$.
The first/second/third term ensures the values/slopes/curvatures of~$T_2$ and~$f$ match at~$\bm{a}$.

\end{vbframe}


\begin{vbframe}{Taylor's theorem (multivariate)}

The theorem for general order~$k$ requires a more involved notation.


    \textbf{Taylor's theorem ($k$-th order):} If $f \in \mathcal{C}^k$, it holds that
    \begin{equation*}
        f(\xv) = \underbrace{\sum_{|\bm{\alpha}| \le k} \frac{D^{\bm{\alpha}} f(\bm{a})}{{\bm{\alpha}}!} (\xv - \bm{a})^{\bm{\alpha}}}_{T_k(\xv, \bm{a})} + R_k(\xv, \bm{a})
    \end{equation*}
    with $R_k(\xv, \bm{a}) = \littleo(\|\xv-\bm{a}\|^k)$ as~$\xv \to \bm{a}$.


\textbf{Notation:} Multi-index~$\bm{\alpha} \in \N^d$

\begin{minipage}[t]{0.49\linewidth}
    \begin{itemize}
        \item $|\bm{\alpha}| = \alpha_1 + \cdots + \alpha_d$
        \item $\bm{\alpha}! = \alpha_1! \cdots \alpha_d!$
    \end{itemize}
\end{minipage}
\begin{minipage}[t]{0.49\linewidth}
    \begin{itemize}
        \item $\xv^{\bm{\alpha}} = x_1^{\alpha_1} \cdots x_d^{\alpha_d}$
        \item $D^{\bm{\alpha}} f = \frac{\partial^{|\bm{\alpha}|} f}{\partial x_1^{\alpha_1} \cdots \partial x_d^{\alpha_d}}$
    \end{itemize}
\end{minipage}

\framebreak

Let us check for bivariate~$f$ ($d=2$).
For $|\bm{\alpha}| \le 1$, we have

\begin{table}
    \centering
    \begin{tabular}{c|c||c|c|c|c}
        $\alpha_1$ & $\alpha_2$ & $|\bm{\alpha}|$ & $D^{\bm{\alpha}} f$ & $\bm{\alpha}!$ & $(\xv-\bm{a})^{\bm{\alpha}}$ \\ \hline\hline
        0 & 0 & 0 & $f$                         & 1 & 1          \\ \hline
        1 & 0 & 1 & $\partial f / \partial x_1$ & 1 & $x_1-a_1$  \\ \hline
        0 & 1 & 1 & $\partial f / \partial x_2$ & 1 & $x_2-a_2$
    \end{tabular}
\end{table}

and therefore

\vspace{-\baselineskip}

\begin{align*}
    T_1(\xv,\bm{a}) &= \frac{f(\bm{a})}{1} \cdot 1 + \frac{\partial f(\bm{a})}{\partial x_1} (x_1 - a_1) + \frac{\partial f(\bm{a})}{\partial x_2} (x_2 - a_2) \\
    &= f(\bm{a}) + \begin{pmatrix}\frac{\partial f(\bm{a})}{\partial x_1} \\ \frac{\partial f(\bm{a})}{\partial x_2}\end{pmatrix}^T \begin{pmatrix}x_1 - a_1 \\ x_2 - a_2\end{pmatrix} \\
    &= f(\bm{a}) + \nabla f(\bm{a})^T (\xv - \bm{a}).
\end{align*}

\end{vbframe}

\begin{vbframe}{Taylor series (multivariate)}

\begin{itemize}
    \item Analogous to univariate case, if~$f \in \mathcal{C}^\infty$, there \textit{might} exist an open ball~$B_r(\bm{a})$ with radius~$r>0$ around~$\bm{a}$ such that the \textbf{Taylor series}
        \begin{equation*}
            \sum_{|\bm{\alpha}| \geq 0} \frac{D^{\bm{\alpha}} f(\bm{a})}{{\bm{\alpha}}!} (\xv - \bm{a})^{\bm{\alpha}}
        \end{equation*}
        converges to~$f$ on~$B_r(\bm{a})$
    \item Even if Taylor series converges, it might not converge to~$f$
    \item Upper bound $R = \sup \left\lbrace r \;|\; \textnormal{Taylor series converges on } B_r(\bm{a}) \right\rbrace$ is called the \textbf{radius of convergence} of Taylor series around~$\bm{a}$
    \item If~$R>0$ and~$f$ analytic, Taylor series converges \textit{absolutely} and \textit{uniformly} to~$f$ on \textit{compact} sets inside~$B_R(\bm{a})$
    \item No general convergence behaviour on boundary of~$B_R(\bm{a})$
\end{itemize}

\end{vbframe}

\endlecture

\end{document}
