\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\input{../../latex-math/ml-mbo}

\title{Optimization in Machine Learning}

\begin{document}

\titlemeta{
Bayesian Optimization
}{
Multicriteria Bayesian Optimization
}{
figure_man/sms_plot.pdf
}{
\item Multicriteria Optimization
\item Taxonomy
\item ParEGO, SMS-EGO, EHI
}

\begin{framev}[fs=small]{Multicriteria Bayesian Optimization}
\splitV[0.4]{
\input{figure_man/black_box.tex}
}{
$$
f: \mathcal{S} \rightarrow \R^m
$$
$$
\min \limits_{\xv \in \mathcal{S}} f(\xv) = ( f_1(\xv), \ldots, f_m(\xv) )
$$
\begin{itemize}
\item A configuration $\xv$ \textbf{dominates} ($\prec$) $\tilde{\xv}$ if
$$
\forall i \in \{ 1, \ldots, m\}:\; f_i(\xv) \leq f_i(\tilde{\xv})
$$
$$
\text{and}~\exists j \in \{1, \ldots, m\}:\; f_j(\xv) < f_j(\tilde{\xv})
$$
\item Set of non-dominated solutions:
$$
\mathcal{P} := \{\xv \in \mathcal{S} | \nexists \tilde{\xv} \in \mathcal{S}: \tilde{\xv} \prec \xv \}
$$
\item Pareto set $\mathcal{P}$, Pareto front $\mathcal{F} = f(\mathcal{P})$
\item{Goal:} Find $\hat{\mathcal{P}}$ of non-dominated points that estimates the true Pareto set $\mathcal{P}$
\end{itemize}
}
\end{framev}


\begin{framev}{Multicriteria Bayesian Optimization}
Example Pareto front:
\vfill
\imageC[0.8]{figure_man/multicrit_0.png}
\end{framev}


\begin{framev}[fs=small]{Multicriteria Bayesian Optimization}
The most popular quality indicator is the hypervolume indicator (also called dominated hypervolume or $\mathcal{S}$-metric).\\
\vspace{1em}
The hypervolume, $\operatorname{HV}$, of an approximation of the Pareto front $\hat{\mathcal{F}} = f(\hat{\mathcal{P}})$ can be defined as the combined volume of the dominated hypercubes $\text{domHC}_{\bm{r}}$ of all solution points $\xv \in \hat{\mathcal{P}}$ regarding a reference point $\bm{r}$, i.e.,
$$
\operatorname{HV}_{\bm{r}}(\hat{\mathcal{P}}) := \mu\left(\bigcup_{\xv \in \hat{\mathcal{P}}}\text{domHC}_{\bm{r}}(\xv)\right)
$$
where $\mu$ is the Lebesgue measure and the dominated hypercube is given as:
$$
\text{domHC}_{\bm{r}}(\xv) := \{\uv \in \R^m~|~ f_i(\xv) \leq \uv_i \leq \bm{r}_i\;\forall i \in \{1, \dots, m\}\}
$$
\end{framev}


\begin{framev}{Multicriteria Bayesian Optimization}
Hypervolume example:
\vfill
\imageC[0.7]{figure_man/multicrit_1.png}
Reference point $\bm{r}$ in red, estimated Pareto front $\hat{\mathcal{F}}$ in black, corresponding $\operatorname{HV}_{\bm{r}}(\hat{\mathcal{P}})$ is given by the grey area
\end{framev}


\begin{framev}{Taxonomy}
\imageC[0.7]{figure_man/FlowchartMBMO.pdf}
\vfill
%TODO: source
Horn, Wagner, Bischl et al. (2014).
\end{framev}

\begin{framev}{ParEGO}
\imageC[0.8]{figure_man/FlowchartMBMO_parego.pdf}
\end{framev}


\begin{framev}{ParEGO}
\begin{enumerate}
\item Scalarize standardized objectives using the augmented Tchebycheff norm
$$
\max\limits_{i \in \{1, \ldots, m\}} w_i f_i(\xv) + \rho \sum\limits_{i = 1}^m w_i f_i(\xv)
$$
with weight vector $\wv$ drawn uniformly from the set of evenly distributed weight vectors $\mathcal{W}$
\item Fit SM on the scalarized objective function
\item Proceed to use any standard single-objective acquisition function (EI, PI, LCB, ...)
\end{enumerate}
\end{framev}


\begin{framev}{ParEGO}
ParEGO Example, initial design and true Pareto front in black ...
\vfill
\imageC[0.8]{figure_man/multicrit_2.png}
\end{framev}


\begin{framev}{ParEGO}
... standardize objectives, obtain scalarized objective via augmented Tchebycheff norm, fit SM and optimize EI ...
\vfill
\imageC[1]{figure_man/multicrit_3.png}
\end{framev}


\begin{framev}{ParEGO}
... note that the specific scalarization is different at each iteration!
\vfill
\imageC[1]{figure_man/multicrit_4.png}
The grey point visualizes the candidate we choose to evaluate in the previous iteration
\end{framev}


\begin{framev}{SMS-EGO}
\imageC[0.8]{figure_man/FlowchartMBMO_sms.pdf}
\end{framev}

\foreach \figbase in {hv_plot, hv_contr_plot, sms_plot} {
\begin{framev}{SMS-EGO}
Individual models for each objective $f_i$\\
\vspace{1em}
Single-objective optimization of aggregating acquisition function: \\
Calculate contribution of the confidence bound of candidate to the current front approximation
\splitV[0.55]{
\begin{itemize}
\item Calculate LCB for each objective
\item Measure contribution with regard to the hypervolume improvement
\item For $\varepsilon$-dominated ($\prec_{\varepsilon}$) solutions, a penalty is added
\end{itemize}
}{
\imageC[1]{figure_man/\figbase.pdf}
}
\end{framev}
}

\begin{framei}{Outlook}
\item Many more options exist:
\begin{itemize}
\item Expected Hypervolume Improvement
\item Multi-EGO
\item Entropy based: PESMO, MESMO
\item ...
\end{itemize}
\end{framei}

\endlecture
\end{document}
